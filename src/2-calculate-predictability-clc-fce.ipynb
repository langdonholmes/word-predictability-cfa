{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10725d95",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b779b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA RTX A6000\n",
      "GPU Memory: 50.93 GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from predictor import Predictor\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "# Check CUDA availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\n",
    "        f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\"\n",
    "    )\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a210569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original docbin...\n",
      "Loaded 2482 original documents\n",
      "Loading corrected docbin...\n",
      "Loaded 2482 corrected documents\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Load the CLC-FCE docbins\n",
    "docbin_path_original = \"../data/clc-fce-docbins/original.docbin\"\n",
    "docbin_path_corrected = \"../data/clc-fce-docbins/corrected.docbin\"\n",
    "\n",
    "print(\"Loading original docbin...\")\n",
    "docbin_original = DocBin().from_disk(docbin_path_original)\n",
    "docs_original = list(docbin_original.get_docs(nlp.vocab))\n",
    "print(f\"Loaded {len(docs_original)} original documents\")\n",
    "\n",
    "print(\"Loading corrected docbin...\")\n",
    "docbin_corrected = DocBin().from_disk(docbin_path_corrected)\n",
    "docs_corrected = list(docbin_corrected.get_docs(nlp.vocab))\n",
    "print(f\"Loaded {len(docs_corrected)} corrected documents\")\n",
    "\n",
    "assert len(docs_original) == len(docs_corrected), \"Docbins must have same number of docs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36d548a",
   "metadata": {},
   "source": [
    "## 2. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68650008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading answerdotai/ModernBERT-base...\n",
      "✓ ModernBERT loaded\n"
     ]
    }
   ],
   "source": [
    "# Load ModernBERT model and tokenizer\n",
    "model_name = \"answerdotai/ModernBERT-base\"\n",
    "print(f\"Loading {model_name}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "print(\"✓ ModernBERT loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ac0035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor initialized:\n",
      "  Model type: masked\n",
      "  Window size: 64\n",
      "  Batch size: 32\n",
      "  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize predictor\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "window_size = 64\n",
    "batch_size = 32\n",
    "\n",
    "predictor = Predictor(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    model_type=\"masked\",\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Predictor initialized:\")\n",
    "print(\"  Model type: masked\")\n",
    "print(f\"  Window size: {window_size}\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7365e295",
   "metadata": {},
   "source": [
    "## 3. Process Documents and Calculate Predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c719f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2482 original documents...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating predictability (original): 100%|██████████| 2482/2482 [12:21<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2482 corrected documents...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating predictability (corrected): 100%|██████████| 2482/2482 [11:33<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Processing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def process_docs(docs, label):\n",
    "    results = {\"doc_id\": [], \"mean_loss\": [], \"mean_prob\": [], \"mean_entropy\": []}\n",
    "    \n",
    "    print(f\"Processing {len(docs)} {label} documents...\\n\")\n",
    "    \n",
    "    for idx, doc in tqdm(enumerate(docs), total=len(docs), desc=f\"Calculating predictability ({label})\"):\n",
    "        text = doc.text\n",
    "        \n",
    "        # Skip if text is empty\n",
    "        if not text.strip():\n",
    "            results[\"doc_id\"].append(idx)\n",
    "            results[\"mean_loss\"].append(None)\n",
    "            results[\"mean_prob\"].append(None)\n",
    "            results[\"mean_entropy\"].append(None)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Calculate predictability\n",
    "            doc_pred = predictor(doc, window_size=window_size)\n",
    "            \n",
    "            # Store aggregate metrics\n",
    "            results[\"doc_id\"].append(idx)\n",
    "            results[\"mean_loss\"].append(doc_pred.mean_loss)\n",
    "            results[\"mean_prob\"].append(\n",
    "                sum(t.mean_prob for t in doc_pred) / len(doc_pred)\n",
    "            )\n",
    "            results[\"mean_entropy\"].append(doc_pred.mean_entropy)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing doc {idx}: {e}\")\n",
    "            results[\"doc_id\"].append(idx)\n",
    "            results[\"mean_loss\"].append(None)\n",
    "            results[\"mean_prob\"].append(None)\n",
    "            results[\"mean_entropy\"].append(None)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Process original docs\n",
    "df_original = process_docs(docs_original, \"original\")\n",
    "\n",
    "# Process corrected docs\n",
    "df_corrected = process_docs(docs_corrected, \"corrected\")\n",
    "\n",
    "print(\"\\n✓ Processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c4fe4",
   "metadata": {},
   "source": [
    "## 4. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a9234b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics for original predictability metrics:\n",
      "\n",
      "         mean_loss    mean_prob  mean_entropy\n",
      "count  2482.000000  2482.000000   2482.000000\n",
      "mean      1.706858     0.528374      1.646216\n",
      "std       0.399799     0.068585      0.337173\n",
      "min       0.700076     0.140778      0.851641\n",
      "25%       1.423229     0.485645      1.413056\n",
      "50%       1.665526     0.534930      1.593374\n",
      "75%       1.936759     0.575824      1.833408\n",
      "max       4.844044     0.721060      4.581869\n",
      "\n",
      "Summary statistics for corrected predictability metrics:\n",
      "\n",
      "         mean_loss    mean_prob  mean_entropy\n",
      "count  2482.000000  2482.000000   2482.000000\n",
      "mean      1.247179     0.601502      1.332564\n",
      "std       0.253283     0.050147      0.222421\n",
      "min       0.557426     0.338495      0.742476\n",
      "25%       1.077096     0.572559      1.182228\n",
      "50%       1.222371     0.605499      1.307154\n",
      "75%       1.377344     0.634809      1.441542\n",
      "max       2.777417     0.753488      2.744214\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "print(\"Summary statistics for original predictability metrics:\\n\")\n",
    "print(df_original[[\"mean_loss\", \"mean_prob\", \"mean_entropy\"]].describe())\n",
    "\n",
    "print(\"\\nSummary statistics for corrected predictability metrics:\\n\")\n",
    "print(df_corrected[[\"mean_loss\", \"mean_prob\", \"mean_entropy\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc276aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Original results saved to: ../data/clc_fce_predictability_original.csv\n",
      "✓ Corrected results saved to: ../data/clc_fce_predictability_corrected.csv\n",
      "  Total docs: 2482\n"
     ]
    }
   ],
   "source": [
    "# Save to files\n",
    "output_path_original = \"../data/clc_fce_predictability_original.csv\"\n",
    "output_path_corrected = \"../data/clc_fce_predictability_corrected.csv\"\n",
    "\n",
    "df_original.to_csv(output_path_original, index=False)\n",
    "df_corrected.to_csv(output_path_corrected, index=False)\n",
    "\n",
    "print(f\"✓ Original results saved to: {output_path_original}\")\n",
    "print(f\"✓ Corrected results saved to: {output_path_corrected}\")\n",
    "print(f\"  Total docs: {len(df_original)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880be9c4",
   "metadata": {},
   "source": [
    "## 5. Quick Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f60066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in original:\n",
      "mean_loss       0\n",
      "mean_prob       0\n",
      "mean_entropy    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in corrected:\n",
      "mean_loss       0\n",
      "mean_prob       0\n",
      "mean_entropy    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for any missing values\n",
    "print(\"Missing values in original:\")\n",
    "print(df_original[[\"mean_loss\", \"mean_prob\", \"mean_entropy\"]].isna().sum())\n",
    "\n",
    "print(\"\\nMissing values in corrected:\")\n",
    "print(df_corrected[[\"mean_loss\", \"mean_prob\", \"mean_entropy\"]].isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
