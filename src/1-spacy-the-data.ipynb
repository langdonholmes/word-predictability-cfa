{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b96411-11dd-4035-a5ba-036a06cc87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from lxml import etree\n",
    "import spacy\n",
    "from spacy.tokens import DocBin, Doc, Span\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize spaCy\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Set up custom attributes for error spans\n",
    "if not Span.has_extension(\"correction\"):\n",
    "    Span.set_extension(\"correction\", default=None)\n",
    "if not Span.has_extension(\"original\"):\n",
    "    Span.set_extension(\"original\", default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662f262e-f046-4982-ac74-faaee704a503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1249 XML files\n",
      "First file: ../data/fce-released-dataset/dataset/0100_2000_12/.ipynb_checkpoints/doc1000-checkpoint.xml\n"
     ]
    }
   ],
   "source": [
    "# Collect all XML files\n",
    "dataset_dir = Path(\"../data/fce-released-dataset/dataset/\")\n",
    "xml_files = sorted(dataset_dir.glob(\"**/doc*.xml\"))\n",
    "\n",
    "print(f\"Found {len(xml_files)} XML files\")\n",
    "print(f\"First file: {xml_files[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16a88b9-1421-4555-b5ec-0b8320c0e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_find_text(element, path, default=None):\n",
    "    \"\"\"\n",
    "    Safely find an XML element and get its text.\n",
    "\n",
    "    Returns default if element not found or has no text.\n",
    "    \"\"\"\n",
    "    found = element.find(path)\n",
    "    if found is not None and found.text is not None:\n",
    "        return found.text\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "082a5380-9633-4fa4-8716-0e15c57cbe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_errors(\n",
    "    element, original_chars, corrected_chars, errors, orig_offset=0, corr_offset=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Recursively extract text and error annotations from XML element.\n",
    "\n",
    "    Args:\n",
    "        element: lxml element to process\n",
    "        original_chars: list to accumulate original text characters\n",
    "        corrected_chars: list to accumulate corrected text characters\n",
    "        errors: list to accumulate error annotations\n",
    "        orig_offset: current offset in original text\n",
    "        corr_offset: current offset in corrected text\n",
    "\n",
    "    Returns:\n",
    "        tuple: (new_orig_offset, new_corr_offset)\n",
    "    \"\"\"\n",
    "    # Add any text directly in this element\n",
    "    if element.text:\n",
    "        text = element.text\n",
    "        original_chars.append(text)\n",
    "        corrected_chars.append(text)\n",
    "        orig_offset += len(text)\n",
    "        corr_offset += len(text)\n",
    "\n",
    "    # Process child elements\n",
    "    for child in element:\n",
    "        if child.tag == \"NS\":  # Error annotation\n",
    "            error_type = child.get(\"type\")\n",
    "\n",
    "            # Find <i> (incorrect) and <c> (correct) children\n",
    "            i_elem = child.find(\"i\")\n",
    "            c_elem = child.find(\"c\")\n",
    "\n",
    "            incorrect_text = \"\"\n",
    "            correct_text = \"\"\n",
    "\n",
    "            # Record start position in original text\n",
    "            error_start = orig_offset\n",
    "\n",
    "            # Handle nested errors in <i> tag\n",
    "            if i_elem is not None:\n",
    "                # Recursively process incorrect portion\n",
    "                i_chars_orig = []\n",
    "                i_chars_corr = []\n",
    "                nested_errors = []\n",
    "\n",
    "                if i_elem.text:\n",
    "                    i_chars_orig.append(i_elem.text)\n",
    "                    i_chars_corr.append(i_elem.text)\n",
    "\n",
    "                # Process nested NS tags\n",
    "                for nested in i_elem:\n",
    "                    if nested.tag == \"NS\":\n",
    "                        nested_type = nested.get(\"type\")\n",
    "                        nested_i = nested.find(\"i\")\n",
    "                        nested_c = nested.find(\"c\")\n",
    "\n",
    "                        nested_start = len(\"\".join(i_chars_orig))\n",
    "\n",
    "                        if nested_i is not None and nested_i.text:\n",
    "                            i_chars_orig.append(nested_i.text)\n",
    "                            if nested_i.tail:\n",
    "                                i_chars_orig.append(nested_i.tail)\n",
    "\n",
    "                        if nested_c is not None and nested_c.text:\n",
    "                            i_chars_corr.append(nested_c.text)\n",
    "                            if nested_c.tail:\n",
    "                                i_chars_corr.append(nested_c.tail)\n",
    "\n",
    "                        nested_end = len(\"\".join(i_chars_orig))\n",
    "\n",
    "                        # Record nested error (relative to parent error start)\n",
    "                        nested_errors.append(\n",
    "                            {\n",
    "                                \"start\": error_start + nested_start,\n",
    "                                \"end\": error_start + nested_end,\n",
    "                                \"type\": nested_type,\n",
    "                                \"incorrect\": nested_i.text\n",
    "                                if nested_i is not None\n",
    "                                else \"\",\n",
    "                                \"correct\": nested_c.text\n",
    "                                if nested_c is not None\n",
    "                                else \"\",\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                    if nested.tail:\n",
    "                        i_chars_orig.append(nested.tail)\n",
    "                        i_chars_corr.append(nested.tail)\n",
    "\n",
    "                if i_elem.tail:\n",
    "                    i_chars_orig.append(i_elem.tail)\n",
    "                    i_chars_corr.append(i_elem.tail)\n",
    "\n",
    "                incorrect_text = \"\".join(i_chars_orig)\n",
    "\n",
    "                # Add to original text\n",
    "                original_chars.append(incorrect_text)\n",
    "                orig_offset += len(incorrect_text)\n",
    "\n",
    "                # Add nested errors\n",
    "                errors.extend(nested_errors)\n",
    "\n",
    "            # Handle correction\n",
    "            if c_elem is not None:\n",
    "                # Process correction (might also have nested elements)\n",
    "                c_chars = []\n",
    "                if c_elem.text:\n",
    "                    c_chars.append(c_elem.text)\n",
    "                for nested in c_elem:\n",
    "                    if nested.tag == \"NS\":\n",
    "                        nested_c = nested.find(\"c\")\n",
    "                        if nested_c is not None and nested_c.text:\n",
    "                            c_chars.append(nested_c.text)\n",
    "                    if nested.tail:\n",
    "                        c_chars.append(nested.tail)\n",
    "                if c_elem.tail:\n",
    "                    c_chars.append(c_elem.tail)\n",
    "\n",
    "                correct_text = \"\".join(c_chars)\n",
    "                corrected_chars.append(correct_text)\n",
    "                corr_offset += len(correct_text)\n",
    "            else:\n",
    "                # Deletion - nothing in corrected text\n",
    "                pass\n",
    "\n",
    "            # Record the error\n",
    "            error_end = orig_offset\n",
    "            if error_start < error_end:  # Only record if there's actually text\n",
    "                errors.append(\n",
    "                    {\n",
    "                        \"start\": error_start,\n",
    "                        \"end\": error_end,\n",
    "                        \"type\": error_type,\n",
    "                        \"incorrect\": incorrect_text,\n",
    "                        \"correct\": correct_text,\n",
    "                    }\n",
    "                )\n",
    "            elif i_elem is None and c_elem is not None:\n",
    "                # Insertion - no text in original, but text in corrected\n",
    "                errors.append(\n",
    "                    {\n",
    "                        \"start\": error_start,\n",
    "                        \"end\": error_start,  # Zero-width span\n",
    "                        \"type\": error_type,\n",
    "                        \"incorrect\": \"\",\n",
    "                        \"correct\": correct_text,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        elif child.tag == \"p\":\n",
    "            # Paragraph - recurse\n",
    "            orig_offset, corr_offset = extract_text_and_errors(\n",
    "                child, original_chars, corrected_chars, errors, orig_offset, corr_offset\n",
    "            )\n",
    "            # Add newline after paragraph\n",
    "            original_chars.append(\"\\n\")\n",
    "            corrected_chars.append(\"\\n\")\n",
    "            orig_offset += 1\n",
    "            corr_offset += 1\n",
    "\n",
    "        # Process tail text (text after this element)\n",
    "        if child.tail:\n",
    "            original_chars.append(child.tail)\n",
    "            corrected_chars.append(child.tail)\n",
    "            orig_offset += len(child.tail)\n",
    "            corr_offset += len(child.tail)\n",
    "\n",
    "    return orig_offset, corr_offset\n",
    "\n",
    "\n",
    "def parse_answer(answer_elem) -> tuple[str, str, list[dict], dict]:\n",
    "    \"\"\"\n",
    "    Parse a single answer element.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (original_text, corrected_text, errors, metadata)\n",
    "    \"\"\"\n",
    "    question_num = safe_find_text(answer_elem, \"question_number\")\n",
    "    exam_score = safe_find_text(answer_elem, \"exam_score\")\n",
    "\n",
    "    if question_num is None or exam_score is None:\n",
    "        raise ValueError(f\"Missing question_number or exam_score\")\n",
    "\n",
    "    # Extract text and errors\n",
    "    coded_answer = answer_elem.find(\"coded_answer\")\n",
    "    if coded_answer is None:\n",
    "        raise ValueError(\"Missing coded_answer element\")\n",
    "\n",
    "    original_chars = []\n",
    "    corrected_chars = []\n",
    "    errors = []\n",
    "\n",
    "    extract_text_and_errors(coded_answer, original_chars, corrected_chars, errors)\n",
    "\n",
    "    original_text = \"\".join(original_chars).strip()\n",
    "    corrected_text = \"\".join(corrected_chars).strip()\n",
    "\n",
    "    metadata = {\"question_number\": question_num, \"exam_score\": exam_score}\n",
    "\n",
    "    return original_text, corrected_text, errors, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10537a13-0f46-4cff-94b2-433cb7eb270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fce_xml(xml_path: Path) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Parse an FCE XML file and extract all answers with metadata.\n",
    "\n",
    "    Returns:\n",
    "        list of dicts, each containing parsed answer data\n",
    "    \"\"\"\n",
    "    tree = etree.parse(str(xml_path))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Extract learner metadata\n",
    "    head = root.find(\".//head\")\n",
    "    if head is None:\n",
    "        raise ValueError(f\"No head element found in {xml_path}\")\n",
    "\n",
    "    doc_id = head.get(\"sortkey\", \"unknown\")\n",
    "\n",
    "    candidate = head.find(\"candidate\")\n",
    "    if candidate is None:\n",
    "        raise ValueError(f\"No candidate element found in {xml_path}\")\n",
    "\n",
    "    language = safe_find_text(candidate, \".//language\", \"Unknown\")\n",
    "    age = safe_find_text(candidate, \".//age\", \"Unknown\")\n",
    "    overall_score = safe_find_text(candidate, \"score\")\n",
    "\n",
    "    # Parse each answer\n",
    "    text_elem = head.find(\"text\")\n",
    "    if text_elem is None:\n",
    "        raise ValueError(f\"No text element found in {xml_path}\")\n",
    "\n",
    "    answers = []\n",
    "\n",
    "    for i in range(1, 10):  # FCE has up to 5 answers typically, but be safe\n",
    "        answer_elem = text_elem.find(f\"answer{i}\")\n",
    "        if answer_elem is None:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            original_text, corrected_text, errors, answer_meta = parse_answer(\n",
    "                answer_elem\n",
    "            )\n",
    "\n",
    "            answers.append(\n",
    "                {\n",
    "                    \"doc_id\": doc_id,\n",
    "                    \"l1\": language,\n",
    "                    \"age\": age,\n",
    "                    \"overall_score\": overall_score,\n",
    "                    \"question_number\": answer_meta[\"question_number\"],\n",
    "                    \"exam_score\": answer_meta[\"exam_score\"],\n",
    "                    \"original_text\": original_text,\n",
    "                    \"corrected_text\": corrected_text,\n",
    "                    \"errors\": errors,\n",
    "                }\n",
    "            )\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: Skipping answer {i} in {xml_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not answers:\n",
    "        raise ValueError(f\"No valid answers found in {xml_path}\")\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b89e4b-17a2-4663-98fa-c2ce22a58427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 answers in sample file\n",
      "\n",
      "Answer 1:\n",
      "  Question: 1\n",
      "  Score: 2.3\n",
      "  Errors: 8\n",
      "  Original text preview: DECEMBER 12TH\n",
      "\n",
      "          PRINCIPAL MR. ROBERTSON\n",
      "\n",
      "          DEAR SIR,\n",
      "\n",
      "          I WANT TO THAK YOU FOR PREPARING SUCH A GOOD PROGRAMME FOR US AND ESPECIALLY FOR TAKING US TO THE RIVER TRIP TO GREENWICH. I WOULD LIKE TO KNOW IF THERE IS ANY CHANCE OF CHANGING THE PROGRAMME BECAUSE WE HAVE FOUND A VERY INTERESTING ACTIVITY TO DO ON TUESDAY 14 MARCH. IT CONSISTS ON VISITING THE LONDON FASHION AND LEISURE SHOW IN THE CENTRAL EXHIBITION HALL. I THINK IT'S A GREAT OPPORTUNITY TO MAKE GREATER USE OF OUR KNOWLEDGE OF  ENGLISH LANGUAGE. ON THE OTHER HAND, WE COULD LEARN THE DIFFERENT WAYS TO GET TO THE CENTRAL EXHIBITION HALL.\n",
      "\n",
      "          I SUGGEST THAT WE SHOULD GO TO THE NATIONAL ART GALLERY IN THE MORNING AND INSTEAD OF HAVING THE AFTERNOON FREE WE COULD GO TO THE FASHION AND LEISURE SHOW.\n",
      "\n",
      "          I WILL BE WRITING ANXIOUSLY FOR YOUR RESPONSE.\n",
      "\n",
      "          YOURS FAITHFULLY...\n",
      "  Corrected text preview: DECEMBER 12TH\n",
      "\n",
      "          PRINCIPAL MR. ROBERTSON\n",
      "\n",
      "          DEAR SIR,\n",
      "\n",
      "          I WANT TO THANK YOU FOR PREPARING SUCH A GOOD PROGRAMME FOR US AND ESPECIALLY FOR TAKING US ON THE RIVER TRIP TO GREENWICH. I WOULD LIKE TO KNOW IF THERE IS ANY CHANCE OF CHANGING THE PROGRAMME BECAUSE WE HAVE FOUND A VERY INTERESTING ACTIVITY TO DO ON TUESDAY 14 MARCH. IT INVOLVES VISITING THE LONDON FASHION AND LEISURE SHOW AT THE CENTRAL EXHIBITION HALL. I THINK IT'S A GREAT OPPORTUNITY TO MAKE GREATER USE OF OUR KNOWLEDGE OF THE ENGLISH LANGUAGE. ALSO, WE COULD LEARN THE DIFFERENT WAYS TO GET TO THE CENTRAL EXHIBITION HALL.\n",
      "\n",
      "          I SUGGEST THAT WE SHOULD GO TO THE NATIONAL ART GALLERY IN THE MORNING AND INSTEAD OF HAVING THE AFTERNOON FREE WE COULD GO TO THE FASHION AND LEISURE SHOW.\n",
      "\n",
      "          I WILL BE WAITING ANXIOUSLY FOR YOUR RESPONSE.\n",
      "\n",
      "          YOURS FAITHFULLY...\n",
      "\n",
      "Answer 2:\n",
      "  Question: 2\n",
      "  Score: 5.1\n",
      "  Errors: 12\n",
      "  Original text preview: (FAMOUS PEOPLE, SUCH AS POLITICIANS AND FILM STARS, DESERVE TO HAVE A PRIVATE LIFE WITHOUT JOURNALISTS FOLLOWING THEM ALL THE TIME)\n",
      "\n",
      "          FAMOUS PEOPLE SUCH AS SINGERS, FILM STARS, ETC ARE ALWAYS THE CENTRE OF ATTENTION. AS SOME OF THEM ARE CONSIDERED IDOLS, THEIR FANS WANT TO KNOW HOW THEY ACT IN THEIR PRIVATE LIVES, WITH THEIR FAMILY OR FRIENDS. AS A RESPONSE TO THIS DEMAND OF INFORMATION, JOURNALISTS FOLLOW FAMOUS PEOPLE DAY AND NIGHT IN MANY DIFFERENT WAYS, FOR EXAMPLE, CHASING THEIR CARS, TAKING PHOTOGRAPHS OR BREAKING INTO THEIR HOUSES WHILE THEY ARE ON HOLIDAYS.\n",
      "\n",
      "          THIS SITUATION AFFECTS FAMOUS PERSONAL LIVES BECAUSE THEY ARE NOT ALLOWED TO HAVE  PRIVACY\n",
      "\n",
      "          THE MOST IMPORTANT THING IS THAT, ALTHOUGH THEY ARE FAMOUS, THEY ARE JUST NORMAL PEOPLE THAT DESERVE TO HAVE A PRIVATE LIFE WITHOUT JOURNALISTS AND FANS FOLLOWING THEM ALL THE TIME, AND ON THE OTHER HAND PEOPLE HAVE TO LEARN TO RESPECT THE FAMOUS  RIGHT TO KEEP THEIR PERSONAL LIVES IN SECRET.\n",
      "\n",
      "          I...\n",
      "  Corrected text preview: (FAMOUS PEOPLE, SUCH AS POLITICIANS AND FILM STARS, DESERVE TO HAVE A PRIVATE LIFE WITHOUT JOURNALISTS FOLLOWING THEM ALL THE TIME)\n",
      "\n",
      "          FAMOUS PEOPLE SUCH AS SINGERS, FILM STARS, ETC, ARE ALWAYS THE CENTRE OF ATTENTION. AS SOME OF THEM ARE CONSIDERED IDOLS, THEIR FANS WANT TO KNOW HOW THEY BEHAVE IN THEIR PRIVATE LIVES, WITH THEIR FAMILY OR FRIENDS. AS A RESPONSE TO THIS DEMAND FOR INFORMATION, JOURNALISTS FOLLOW FAMOUS PEOPLE DAY AND NIGHT IN MANY DIFFERENT WAYS, FOR EXAMPLE, CHASING THEIR CARS, TAKING PHOTOGRAPHS OR BREAKING INTO THEIR HOUSES WHILE THEY ARE ON HOLIDAY.\n",
      "\n",
      "          THIS SITUATION AFFECTS FAMOUS PEOPLE BECAUSE THEY ARE NOT ALLOWED TO HAVE ANY PRIVACY.\n",
      "\n",
      "          THE MOST IMPORTANT THING IS THAT, ALTHOUGH THEY ARE FAMOUS, THEY ARE JUST NORMAL PEOPLE THAT DESERVE TO HAVE A PRIVATE LIFE WITHOUT JOURNALISTS AND FANS FOLLOWING THEM ALL THE TIME, AND ON THE OTHER HAND PEOPLE HAVE TO LEARN TO RESPECT THE THE RIGHT OF THE FAMOUS TO KEEP THEIR PERSONAL LIVES  SECRET.\n",
      "\n",
      "   ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on the sample file\n",
    "sample_file = Path(\"../data/fce-released-dataset/dataset/0100_2000_12/doc1000.xml\")\n",
    "sample_answers = parse_fce_xml(sample_file)\n",
    "\n",
    "print(f\"Found {len(sample_answers)} answers in sample file\\n\")\n",
    "\n",
    "for i, answer in enumerate(sample_answers):\n",
    "    print(f\"Answer {i+1}:\")\n",
    "    print(f\"  Question: {answer['question_number']}\")\n",
    "    print(f\"  Score: {answer['exam_score']}\")\n",
    "    print(f\"  Errors: {len(answer['errors'])}\")\n",
    "    print(f\"  Original text preview: {answer['original_text'][:1_000]}...\")\n",
    "    print(f\"  Corrected text preview: {answer['corrected_text'][:1_000]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb8e8b5-649e-491e-ae81-012361529235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_spacy_docs(answer_data: dict) -> tuple[Doc, Doc, dict]:\n",
    "    \"\"\"\n",
    "    Create SpaCy Doc objects for original and corrected texts.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (original_doc, corrected_doc, diagnostics)\n",
    "    \"\"\"\n",
    "    diagnostics = {\"failed_spans\": [], \"total_errors\": len(answer_data[\"errors\"])}\n",
    "\n",
    "    # Count error types from the annotations\n",
    "    error_type_counts = defaultdict(int)\n",
    "    for error in answer_data[\"errors\"]:\n",
    "        error_type_counts[error[\"type\"]] += 1\n",
    "\n",
    "    # Create original doc with errors\n",
    "    original_doc = nlp(answer_data[\"original_text\"])\n",
    "\n",
    "    # Add metadata\n",
    "    original_doc.user_data[\"doc_id\"] = answer_data[\"doc_id\"]\n",
    "    original_doc.user_data[\"l1\"] = answer_data[\"l1\"]\n",
    "    original_doc.user_data[\"age\"] = answer_data[\"age\"]\n",
    "    original_doc.user_data[\"overall_score\"] = answer_data[\"overall_score\"]\n",
    "    original_doc.user_data[\"question_number\"] = answer_data[\"question_number\"]\n",
    "    original_doc.user_data[\"exam_score\"] = answer_data[\"exam_score\"]\n",
    "    original_doc.user_data[\"error_counts\"] = dict(\n",
    "        error_type_counts\n",
    "    )  # Convert to regular dict\n",
    "    original_doc.user_data[\"total_errors\"] = sum(error_type_counts.values())\n",
    "\n",
    "    # Add error spans\n",
    "    error_spans = []\n",
    "    for error in answer_data[\"errors\"]:\n",
    "        # Try different alignment modes\n",
    "        span = original_doc.char_span(\n",
    "            error[\"start\"], error[\"end\"], label=error[\"type\"], alignment_mode=\"expand\"\n",
    "        )\n",
    "\n",
    "        # If expand doesn't work, try contract\n",
    "        if span is None:\n",
    "            span = original_doc.char_span(\n",
    "                error[\"start\"],\n",
    "                error[\"end\"],\n",
    "                label=error[\"type\"],\n",
    "                alignment_mode=\"contract\",\n",
    "            )\n",
    "\n",
    "        if span is not None:\n",
    "            span._.correction = error[\"correct\"]\n",
    "            span._.original = error[\"incorrect\"]\n",
    "            error_spans.append(span)\n",
    "        else:\n",
    "            # Log failed span for diagnostics\n",
    "            text_snippet = answer_data[\"original_text\"][\n",
    "                max(0, error[\"start\"] - 10) : min(\n",
    "                    len(answer_data[\"original_text\"]), error[\"end\"] + 10\n",
    "                )\n",
    "            ]\n",
    "            diagnostics[\"failed_spans\"].append(\n",
    "                {\n",
    "                    \"doc_id\": answer_data[\"doc_id\"],\n",
    "                    \"start\": error[\"start\"],\n",
    "                    \"end\": error[\"end\"],\n",
    "                    \"type\": error[\"type\"],\n",
    "                    \"text\": error[\"incorrect\"],\n",
    "                    \"context\": text_snippet,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    original_doc.spans[\"errors\"] = error_spans\n",
    "    diagnostics[\"successful_spans\"] = len(error_spans)\n",
    "\n",
    "    # Create corrected doc (simpler, no error spans)\n",
    "    corrected_doc = nlp(answer_data[\"corrected_text\"])\n",
    "\n",
    "    # Add same metadata to corrected doc (including error counts)\n",
    "    corrected_doc.user_data[\"doc_id\"] = answer_data[\"doc_id\"]\n",
    "    corrected_doc.user_data[\"l1\"] = answer_data[\"l1\"]\n",
    "    corrected_doc.user_data[\"age\"] = answer_data[\"age\"]\n",
    "    corrected_doc.user_data[\"overall_score\"] = answer_data[\"overall_score\"]\n",
    "    corrected_doc.user_data[\"question_number\"] = answer_data[\"question_number\"]\n",
    "    corrected_doc.user_data[\"exam_score\"] = answer_data[\"exam_score\"]\n",
    "    corrected_doc.user_data[\"error_counts\"] = dict(error_type_counts)  # Same counts\n",
    "    corrected_doc.user_data[\"total_errors\"] = sum(error_type_counts.values())\n",
    "\n",
    "    # Remove the transformer embeddings to prevent saving them when store_user_data=True\n",
    "    original_doc._.trf_data = None\n",
    "    corrected_doc._.trf_data = None\n",
    "\n",
    "    return original_doc, corrected_doc, diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20b45457-6d7f-42ab-acf6-7a25ec54cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_files(xml_files: list[Path]) -> tuple[DocBin, DocBin, dict]:\n",
    "    \"\"\"\n",
    "    Process all XML files and create DocBins for original and corrected texts.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (original_docbin, corrected_docbin, stats)\n",
    "    \"\"\"\n",
    "    original_docbin = DocBin(store_user_data=True)\n",
    "    corrected_docbin = DocBin(store_user_data=True)\n",
    "\n",
    "    stats = {\n",
    "        \"total_answers\": 0,\n",
    "        \"total_errors\": 0,\n",
    "        \"successful_spans\": 0,\n",
    "        \"failed_spans\": 0,\n",
    "        \"failed_span_details\": [],\n",
    "    }\n",
    "\n",
    "    for xml_file in tqdm(xml_files, desc=\"Processing XML files\"):\n",
    "        try:\n",
    "            answers = parse_fce_xml(xml_file)\n",
    "\n",
    "            for answer in answers:\n",
    "                orig_doc, corr_doc, diag = create_spacy_docs(answer)\n",
    "\n",
    "                original_docbin.add(orig_doc)\n",
    "                corrected_docbin.add(corr_doc)\n",
    "\n",
    "                stats[\"total_answers\"] += 1\n",
    "                stats[\"total_errors\"] += diag[\"total_errors\"]\n",
    "                stats[\"successful_spans\"] += diag[\"successful_spans\"]\n",
    "                stats[\"failed_spans\"] += len(diag[\"failed_spans\"])\n",
    "                stats[\"failed_span_details\"].extend(diag[\"failed_spans\"])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {xml_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n=== Processing Statistics ===\")\n",
    "    print(f\"Total answers: {stats['total_answers']}\")\n",
    "    print(f\"Total errors annotated: {stats['total_errors']}\")\n",
    "    print(f\"Successful spans: {stats['successful_spans']}\")\n",
    "    print(\n",
    "        f\"Failed spans: {stats['failed_spans']} ({stats['failed_spans']/stats['total_errors']*100:.2f}%)\"\n",
    "    )\n",
    "    print(f\"\\nOriginal DocBin: {len(original_docbin)} docs\")\n",
    "    print(f\"Corrected DocBin: {len(corrected_docbin)} docs\")\n",
    "\n",
    "    return original_docbin, corrected_docbin, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6846f96b-1255-4b12-897c-7cea804e58cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc29585313e4515a559944a90977979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing XML files:   0%|          | 0/1249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping answer 2 in ../data/fce-released-dataset/dataset/0100_2000_12/.ipynb_checkpoints/doc548-checkpoint.xml: Missing question_number or exam_score\n",
      "Warning: Skipping answer 2 in ../data/fce-released-dataset/dataset/0100_2000_12/doc1581.xml: Missing question_number or exam_score\n",
      "Warning: Skipping answer 2 in ../data/fce-released-dataset/dataset/0100_2000_12/doc2302.xml: Missing question_number or exam_score\n",
      "Warning: Skipping answer 2 in ../data/fce-released-dataset/dataset/0100_2000_12/doc548.xml: Missing question_number or exam_score\n",
      "Warning: Skipping answer 2 in ../data/fce-released-dataset/dataset/0102_2000_12/doc1579.xml: Missing question_number or exam_score\n",
      "Warning: Skipping answer 2 in ../data/fce-released-dataset/dataset/0102_2000_12/doc284.xml: Missing question_number or exam_score\n",
      "Warning: Skipping answer 1 in ../data/fce-released-dataset/dataset/0102_2000_12/doc599.xml: Missing question_number or exam_score\n",
      "Warning: Skipping answer 2 in ../data/fce-released-dataset/dataset/0102_2000_12/doc599.xml: Missing question_number or exam_score\n",
      "Error processing ../data/fce-released-dataset/dataset/0102_2000_12/doc599.xml: No valid answers found in ../data/fce-released-dataset/dataset/0102_2000_12/doc599.xml\n",
      "Warning: Skipping answer 2 in ../data/fce-released-dataset/dataset/0102_2000_6/doc2009.xml: Missing question_number or exam_score\n",
      "\n",
      "=== Processing Statistics ===\n",
      "Total answers: 2482\n",
      "Total errors annotated: 53332\n",
      "Successful spans: 52752\n",
      "Failed spans: 580 (1.09%)\n",
      "\n",
      "Original DocBin: 2482 docs\n",
      "Corrected DocBin: 2482 docs\n"
     ]
    }
   ],
   "source": [
    "original_docbin, corrected_docbin, diagnostic = process_all_files(xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c048fe7f-5e29-4f58-a8eb-aac587012efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved original docs to: ../data/clc-fce/original.docbin\n",
      "Saved corrected docs to: ../data/clc-fce/corrected.docbin\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"../data/clc-fce/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save DocBins\n",
    "original_path = output_dir / \"original.docbin\"\n",
    "corrected_path = output_dir / \"corrected.docbin\"\n",
    "\n",
    "original_docbin.to_disk(original_path)\n",
    "corrected_docbin.to_disk(corrected_path)\n",
    "\n",
    "print(f\"Saved original docs to: {original_path}\")\n",
    "print(f\"Saved corrected docs to: {corrected_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d730f217-53ed-44db-85fc-0b302dd6e6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2482 original docs\n",
      "Loaded 2482 corrected docs\n",
      "\n",
      "First original doc:\n",
      "  Text preview: DECEMBER 12TH\n",
      "\n",
      "          PRINCIPAL MR. ROBERTSON\n",
      "\n",
      "          DEAR SIR,\n",
      "\n",
      "          I WANT TO THAK YOU ...\n",
      "  Metadata: {('._.', 'trf_data', None, None): None, 'doc_id': 'TR3*0100*2000*02', 'l1': 'Catalan', 'age': '16-20', 'overall_score': '28.00', 'question_number': '1', 'exam_score': '2.3', 'error_counts': {'S': 1, 'RT': 3, 'RV': 2, 'MD': 1, 'ID': 1}, 'total_errors': 8, ('._.', 'correction', 100, 113): 'THANK', ('._.', 'original', 100, 113): 'THAK', ('._.', 'correction', 179, 184): 'ON', ('._.', 'original', 179, 184): 'TO', ('._.', 'correction', 375, 378): 'IN', ('._.', 'original', 375, 378): 'ON', ('._.', 'correction', 366, 378): 'INVOLVES', ('._.', 'original', 366, 378): 'CONSISTS ON', ('._.', 'correction', 418, 425): 'AT', ('._.', 'original', 418, 425): 'IN', ('._.', 'correction', 525, 533): 'THE', ('._.', 'original', 525, 533): '', ('._.', 'correction', 542, 562): 'ALSO', ('._.', 'original', 542, 562): 'ON THE OTHER HAND', ('._.', 'correction', 824, 833): 'WAITING', ('._.', 'original', 824, 833): 'WRITING'}\n",
      "  Total errors: 8\n",
      "  Error type counts: {'S': 1, 'RT': 3, 'RV': 2, 'MD': 1, 'ID': 1}\n",
      "  Number of error spans: 8\n",
      "\n",
      "  First error span:\n",
      "    Type: S\n",
      "    Original: 'THAK'\n",
      "    Correction: 'THANK'\n",
      "    Span text: 'FOR PREPARING'\n",
      "\n",
      "First corrected doc:\n",
      "  Text preview: DECEMBER 12TH\n",
      "\n",
      "          PRINCIPAL MR. ROBERTSON\n",
      "\n",
      "          DEAR SIR,\n",
      "\n",
      "          I WANT TO THANK YOU...\n",
      "  Total errors (from original): 8\n",
      "  Error type counts: {'S': 1, 'RT': 3, 'RV': 2, 'MD': 1, 'ID': 1}\n",
      "\n",
      "=== Aggregate Error Type Statistics ===\n",
      "Total unique error types: 74\n",
      "\n",
      "Most common error types:\n",
      "  S: 4724\n",
      "  RP: 3514\n",
      "  RV: 3383\n",
      "  RT: 3339\n",
      "  TV: 3326\n",
      "  MD: 2979\n",
      "  MP: 2950\n",
      "  RN: 1837\n",
      "  FV: 1793\n",
      "  R: 1553\n"
     ]
    }
   ],
   "source": [
    "# Load and verify\n",
    "original_loaded = DocBin(store_user_data=True).from_disk(original_path)\n",
    "corrected_loaded = DocBin(store_user_data=True).from_disk(corrected_path)\n",
    "\n",
    "# Test: load first doc from each\n",
    "orig_docs = list(original_loaded.get_docs(nlp.vocab))\n",
    "corr_docs = list(corrected_loaded.get_docs(nlp.vocab))\n",
    "\n",
    "print(f\"Loaded {len(orig_docs)} original docs\")\n",
    "print(f\"Loaded {len(corr_docs)} corrected docs\\n\")\n",
    "\n",
    "# Inspect first doc\n",
    "first_orig = orig_docs[0]\n",
    "print(\"First original doc:\")\n",
    "print(f\"  Text preview: {first_orig.text[:100]}...\")\n",
    "print(f\"  Metadata: {first_orig.user_data}\")\n",
    "print(f\"  Total errors: {first_orig.user_data['total_errors']}\")\n",
    "print(f\"  Error type counts: {first_orig.user_data['error_counts']}\")\n",
    "print(f\"  Number of error spans: {len(first_orig.spans['errors'])}\")\n",
    "\n",
    "if len(first_orig.spans[\"errors\"]) > 0:\n",
    "    first_error = first_orig.spans[\"errors\"][0]\n",
    "    print(f\"\\n  First error span:\")\n",
    "    print(f\"    Type: {first_error.label_}\")\n",
    "    print(f\"    Original: '{first_error._.original}'\")\n",
    "    print(f\"    Correction: '{first_error._.correction}'\")\n",
    "    print(f\"    Span text: '{first_error.text}'\")\n",
    "\n",
    "print(f\"\\nFirst corrected doc:\")\n",
    "print(f\"  Text preview: {corr_docs[0].text[:100]}...\")\n",
    "print(f\"  Total errors (from original): {corr_docs[0].user_data['total_errors']}\")\n",
    "print(f\"  Error type counts: {corr_docs[0].user_data['error_counts']}\")\n",
    "\n",
    "# Show aggregate statistics across all docs\n",
    "print(\"\\n=== Aggregate Error Type Statistics ===\")\n",
    "all_error_counts = defaultdict(int)\n",
    "for doc in orig_docs:\n",
    "    for error_type, count in doc.user_data[\"error_counts\"].items():\n",
    "        all_error_counts[error_type] += count\n",
    "\n",
    "print(f\"Total unique error types: {len(all_error_counts)}\")\n",
    "print(\"\\nMost common error types:\")\n",
    "for error_type, count in sorted(\n",
    "    all_error_counts.items(), key=lambda x: x[1], reverse=True\n",
    ")[:10]:\n",
    "    print(f\"  {error_type}: {count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spacy]",
   "language": "python",
   "name": "conda-env-spacy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
